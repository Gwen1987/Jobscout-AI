# ðŸ•µï¸ JobScout AI

JobScout AI is a neural network-based binary classification project built to detect fraudulent job postings. Using natural language processing (NLP) and TensorFlow, it analyzes job descriptions and titles to predict the likelihood of fraud, aiming to support job seekers by filtering out deceptive listings.

---

## ðŸŒ Live Demo on Hugging Face

Want to test JobScout AI instantly? Try it now on [Hugging Face Spaces](https://huggingface.co/spaces/gwen-s/jobscout-ai)!



**Usage:**

1. Paste a full job posting (title + description) into the textbox.
2. Receive a real-time fraud risk assessment.
3. All submissions are logged internally for future model improvements.

âš ï¸ *This version uses only the job text and flags jobs with a fraud probability â‰¥ 85%.*

---

## ðŸ—“ï¸ Threshold Optimization

JobScout AI optimizes its decision boundary based on precision-recall tradeoffs, selecting a fraud classification threshold of **0.85**. This decision balances strong recall with meaningful precision while minimizing false positives.

| Threshold | Precision  | Recall     | F1 Score   |
| --------- | ---------- | ---------- | ---------- |
| 0.50      | 0.4646     | 0.8678     | 0.6052     |
| 0.60      | 0.4935     | 0.8678     | 0.6292     |
| 0.70      | 0.5261     | 0.8678     | 0.6551     |
| **0.85**  | **0.5781** | **0.8506** | **0.6884** |
| 0.90      | 0.61       | 0.8448     | 0.7084     |

> âœ¨ **Note:** Thresholds >0.90 had slightly better precision but sacrificed recall. Thresholds <0.35 began introducing false positives in low-risk bins.

---

## ðŸ“Š Fraud Risk Binning Justification

The model assigns risk tiers based on predicted fraud probability:

- ðŸ”µ Legit: < 0.35
- ðŸŸ¡ Caution Advised: 0.35â€“0.84
- ðŸ”´ High Risk: â‰¥ 0.85

Bin analysis shows that fraud rates are negligible under 0.35 and begin to rise sharply near the 0.85 mark:

| Probability Bin | Fraud Rate |
| --------------- | ---------- |
| 0.0â€“0.1         | 0.57%      |
| 0.1â€“0.2         | 8.70%      |
| 0.2â€“0.3         | 0.00%      |
| 0.3â€“0.4         | 0.00%      |
| 0.8â€“0.9         | 16.00%     |
| 0.9â€“1.0         | 60.99%     |

ðŸ“„ This confirms **0.35** as an appropriate threshold to initiate caution.

---

## ðŸ“¦ Project Structure

```
JobScout-AI/
â”œâ”€â”€ .gitignore                    # Ignored files for version control
â”œâ”€â”€ EDA.ipynb                     # Exploratory Data Analysis notebook
â”œâ”€â”€ gradio_app.py                # Main Gradio app entry point
â”œâ”€â”€ LICENSE                      # Project license
â”œâ”€â”€ README.md                    # Project overview and usage
â”œâ”€â”€ requirements.txt             # Core project dependencies
â”œâ”€â”€ data/                        # Processed and raw datasets - files excluded from github due to size
â”œâ”€â”€ images/                      # Visualizations and plots
   â”œâ”€â”€ confusion_matrix.png
   â”œâ”€â”€ threshold_optimization.png

â”œâ”€â”€ logs/                        # Evaluation logs and final reports
    â”œâ”€â”€ classification_report.txt
    â”œâ”€â”€ eval_summary.md
    â”œâ”€â”€ jobscout_logs_final.csv
â”œâ”€â”€ models/                      # Model + vectorizer artifacts
   â”œâ”€â”€ archived/                # Archived models
   â”œâ”€â”€ jobscout_tfidf_smoteenn.keras
   â”œâ”€â”€ jobscout_tfidf_vectorizer.pkl
â”œâ”€â”€ notebook/                    # Metric visualizations (Jupyter)
   â”œâ”€â”€ precision_recall_graph.ipynb
â”œâ”€â”€ real_world_examples/         # Real job ads for evaluation
â”œâ”€â”€ scripts/                     # Training and evaluation scripts
   â”œâ”€â”€ analyze_threshold.py
   â”œâ”€â”€ classification_report.py
   â”œâ”€â”€ generate_eval_results.py
   â”œâ”€â”€ merge_training_data.py
   â”œâ”€â”€ split_train_validation.py
   â”œâ”€â”€ train_data_.py

```

---

## ðŸ” Features

- ðŸ¤– **Binary Fraud Classifier** â€” Real vs Fake job posting prediction
- ðŸ§  **Dense Neural Network** â€” Optimized with class weights and dropout layers
- âš–ï¸ **SMOTEENN Resampling** â€” Hybrid oversampling + undersampling strategy
- ðŸ”¹ **Red Flag Booster** â€” Flags phrases often associated with scams
- ðŸ“Š **Metrics Tracking** â€” Accuracy, Precision, Recall, F1, Threshold Tuning

---

## ðŸ§ª Model Testing Summary

| Model Version | Architecture                         | Precision (%) | Recall (%) | Val Accuracy (%) | Val Loss   |
| ------------- | ------------------------------------ | ------------- | ---------- | ---------------- | ---------- |
| v1            | Dense (16x2)                         | 95.05         | 55.49      | 97.71            | 0.0846     |
| v2            | Embedding + Dropout                  | 83.62         | 56.07      | 97.34            | 0.0889     |
| v3            | LSTM + Dropout                       | 51.96         | 84.39      | 95.47            | 0.1464     |
| **v4**        | Dense + Dropout + SMOTEENN + Booster | **57.81**     | **85.06**  | **95.93**        | **0.1394** |

---

## ðŸ› ï¸ Tools & Technologies

- Python, Pandas, NumPy
- TensorFlow, Keras (Dense models)
- Scikit-learn, Imbalanced-learn (SMOTEENN)
- JupyterLab, Matplotlib, Seaborn
- Gradio for web app interface

---

## ðŸ“ Data Source

Dataset: `fake_job_postings.csv` from Kaggle [fake-job-posting-prediction](https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction)

---

## â–¶ï¸ How to Run

1. Clone the repository
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Launch the Gradio app locally:
   ```bash
   python gradio_app.py
   ```

---

## ðŸš€ Future Enhancements

- Add Transformer-based NLP model (e.g., BERT or DistilBERT) for richer contextual understanding

---

## ðŸ§  Author

Gwen Seymour â€” [LinkedIn](https://www.linkedin.com/in/gwen-seymour) | [GitHub](https://github.com/Gwen1987)

> JobScout AI was built to sharpen TensorFlow skills and explore real-world NLP challenges that affect job seekers worldwide.

